{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "# pandas:Data framework library for Python\n",
    "# sklearn: Library to perform machine learning tasks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import sklearn \n",
    "import sklearn.datasets\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_2017 = pd.read_excel(\"PERM_Disclosure_Data_FY17.xlsx\")\n",
    "Data_2015 = pd.read_excel(\"PERM_Disclosure_Data_FY15_Q4.xlsx\")\n",
    "Data_2016 = pd.read_excel(\"PERM_Data_FY16.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_2015.at[8809, 'RI_LOCAL_ETHNIC_PAPER_FROM'] = datetime.strptime('10/22/2014', '%m/%d/%Y')\n",
    "Data_2015.at[29257, 'RI_LOCAL_ETHNIC_PAPER_FROM'] = datetime.strptime('10/06/2014', '%m/%d/%Y')\n",
    "Data_2015.at[86322, 'RI_LOCAL_ETHNIC_PAPER_FROM'] = datetime.strptime('03/09/2015', '%m/%d/%Y')\n",
    "Data_2015['RI_LOCAL_ETHNIC_PAPER_FROM'] = pandas.to_datetime(Data_2015['RI_LOCAL_ETHNIC_PAPER_FROM'])\n",
    "Data_2015['RECR_INFO_SWA_JOB_ORDER_START'] = pandas.to_datetime(Data_2015['RECR_INFO_SWA_JOB_ORDER_START'])\n",
    "Data_2015.at[6306, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('05/26/2014', '%m/%d/%Y')\n",
    "Data_2015.at[8602, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('11/08/2014', '%m/%d/%Y')\n",
    "Data_2015.at[12210, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('05/25/2014', '%m/%d/%Y')\n",
    "Data_2015.at[35208, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('08/30/2013', '%m/%d/%Y')\n",
    "Data_2015.at[41211, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/25/2014', '%m/%d/%Y')\n",
    "Data_2015.at[79773, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('05/19/2014', '%m/%d/%Y')\n",
    "Data_2015.at[80176, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('06/14/2015', '%m/%d/%Y')\n",
    "Data_2015.at[80177, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('06/14/2015', '%m/%d/%Y')\n",
    "Data_2015.at[83651, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('05/26/2013', '%m/%d/%Y')\n",
    "Data_2015['RECR_INFO_SWA_JOB_ORDER_END'] = pandas.to_datetime(Data_2015['RECR_INFO_SWA_JOB_ORDER_END'])\n",
    "Data_2015.at[76114, 'RI_EMPLOYER_WEB_POST_FROM'] = datetime.strptime('04/22/2014', '%m/%d/%Y')\n",
    "Data_2015.at[89154, 'RI_EMPLOYER_WEB_POST_FROM'] = datetime.strptime('05/01/2015', '%m/%d/%Y')\n",
    "Data_2015['RI_EMPLOYER_WEB_POST_FROM'] = pandas.to_datetime(Data_2015['RI_EMPLOYER_WEB_POST_FROM'])\n",
    "Data_2015.at[29489, 'RECR_INFO_PRO_ORG_ADVERT_FROM'] = datetime.strptime('01/01/2013', '%m/%d/%Y')\n",
    "Data_2015['RECR_INFO_PRO_ORG_ADVERT_FROM'] = pandas.to_datetime(Data_2015['RECR_INFO_PRO_ORG_ADVERT_FROM'])\n",
    "Data_2015.at[26192, 'RI_JOB_SEARCH_WEBSITE_FROM'] = datetime.strptime('01/13/2014', '%m/%d/%Y')\n",
    "Data_2015.at[70342, 'RI_JOB_SEARCH_WEBSITE_FROM'] = datetime.strptime('05/02/2014', '%m/%d/%Y')\n",
    "Data_2015.at[83733, 'RI_JOB_SEARCH_WEBSITE_FROM'] = datetime.strptime('11/15/2011', '%m/%d/%Y')\n",
    "Data_2015['RI_JOB_SEARCH_WEBSITE_FROM'] = pandas.to_datetime(Data_2015['RI_JOB_SEARCH_WEBSITE_FROM'])\n",
    "Data_2015.at[24138, 'RI_EMPLOYEE_REFERRAL_PROG_FROM'] = datetime.strptime('12/23/2014', '%m/%d/%Y')\n",
    "Data_2015.at[38262, 'RI_EMPLOYEE_REFERRAL_PROG_FROM'] = datetime.strptime('06/04/2014', '%m/%d/%Y')\n",
    "Data_2015.at[47808, 'RI_EMPLOYEE_REFERRAL_PROG_FROM'] = datetime.strptime('06/25/2014', '%m/%d/%Y')\n",
    "Data_2015['RI_EMPLOYEE_REFERRAL_PROG_FROM'] = pandas.to_datetime(Data_2015['RI_EMPLOYEE_REFERRAL_PROG_FROM'])\n",
    "Data_2015.at[14771, 'RI_CAMPUS_PLACEMENT_FROM'] = datetime.strptime('04/01/2013', '%m/%d/%Y')\n",
    "Data_2015.at[49525, 'RI_CAMPUS_PLACEMENT_FROM'] = datetime.strptime('05/02/2013', '%m/%d/%Y')\n",
    "Data_2015.at[73061, 'RI_CAMPUS_PLACEMENT_FROM'] = datetime.strptime('09/23/2014', '%m/%d/%Y')\n",
    "Data_2015['RI_CAMPUS_PLACEMENT_FROM'] = pandas.to_datetime(Data_2015['RI_CAMPUS_PLACEMENT_FROM'])\n",
    "Data_2017.at[31198, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('03/30/2016', '%m/%d/%Y')\n",
    "Data_2017.at[77798, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('04/26/2017', '%m/%d/%Y')\n",
    "Data_2017.at[92988, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('03/30/2017', '%m/%d/%Y')\n",
    "\n",
    "Data_2017['RECR_INFO_SWA_JOB_ORDER_START'] = pandas.to_datetime(Data_2017['RECR_INFO_SWA_JOB_ORDER_START'])\n",
    "#Data_2017.at[31198, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('03/30/2016', '%m/%d/%Y')\n",
    "#Data_2017.at[77798, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('04/26/2017', '%m/%d/%Y')\n",
    "Data_2017.at[704, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/17/2016', '%m/%d/%Y')\n",
    "Data_2017.at[2932, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('04/13/2016', '%m/%d/%Y')\n",
    "Data_2017.at[18749, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('05/13/2016', '%m/%d/%Y')\n",
    "Data_2017.at[73589, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/05/2017', '%m/%d/%Y')\n",
    "Data_2017.at[82743, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/06/2017', '%m/%d/%Y')\n",
    "Data_2017.at[92390, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/27/2017', '%m/%d/%Y')\n",
    "Data_2017.at[93721, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/27/2017', '%m/%d/%Y')\n",
    "Data_2017.at[96292, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/05/2017', '%m/%d/%Y')\n",
    "Data_2017['RECR_INFO_SWA_JOB_ORDER_END'] = pandas.to_datetime(Data_2017['RECR_INFO_SWA_JOB_ORDER_END'])\n",
    "Data_2016.at[96389, 'RECR_INFO_SWA_JOB_ORDER_START'] = datetime.strptime('03/30/2016', '%m/%d/%Y')\n",
    "Data_2016['RECR_INFO_SWA_JOB_ORDER_START'] = pandas.to_datetime(Data_2016['RECR_INFO_SWA_JOB_ORDER_START'])\n",
    "Data_2016.at[29552, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('06/04/2015', '%m/%d/%Y')\n",
    "Data_2016.at[33362, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/06/2015', '%m/%d/%Y')\n",
    "Data_2016.at[49878, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/02/2015', '%m/%d/%Y')\n",
    "Data_2016.at[60593, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('08/03/2015', '%m/%d/%Y')\n",
    "Data_2016.at[91218, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('11/30/2015', '%m/%d/%Y')\n",
    "Data_2016.at[113096, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/15/2016', '%m/%d/%Y')\n",
    "Data_2016.at[114287, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/30/2016', '%m/%d/%Y')\n",
    "Data_2016.at[120997, 'RECR_INFO_SWA_JOB_ORDER_END'] = datetime.strptime('03/30/2016', '%m/%d/%Y')\n",
    "Data_2016['RECR_INFO_SWA_JOB_ORDER_END'] = pandas.to_datetime(Data_2016['RECR_INFO_SWA_JOB_ORDER_END'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [Data_2015, Data_2016, Data_2017]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "data = data.drop_duplicates()\n",
    "data_raw = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For wages that have a to and from, Im just gonna take the average\n",
    "data_wage = data[['WAGE_OFFER_UNIT_OF_PAY_9089','WAGE_OFFER_FROM_9089','WAGE_OFFER_TO_9089','CASE_STATUS']]\n",
    "#cleaning up the wages of the offer\n",
    "#pd.to_numeric(data_wage['WAGE_OFFER_FROM_9089'])\n",
    "data['WAGE_OFFER_FROM_9089'] = data['WAGE_OFFER_FROM_9089'].apply(lambda word: str(word).replace(\"#\", \"\"))\n",
    "data['WAGE_OFFER_FROM_9089'] = data['WAGE_OFFER_FROM_9089'].apply(lambda word: str(word).replace(\",\", \"\"))\n",
    "data['WAGE_OFFER_FROM_9089'] = data['WAGE_OFFER_FROM_9089'].replace({\"nan\": np.NaN})\n",
    "data['WAGE_OFFER_FROM_9089'] = pd.to_numeric(data['WAGE_OFFER_FROM_9089'])\n",
    "data['WAGE_OFFER_TO_9089'] = data['WAGE_OFFER_TO_9089'].apply(lambda word: str(word).replace(\"#\", \"\"))\n",
    "data['WAGE_OFFER_TO_9089'] = data['WAGE_OFFER_TO_9089'].apply(lambda word: str(word).replace(\",\", \"\"))\n",
    "data['WAGE_OFFER_TO_9089'] = data['WAGE_OFFER_TO_9089'].replace({\"nan\": np.NaN})\n",
    "data['WAGE_OFFER_TO_9089'] = pd.to_numeric(data['WAGE_OFFER_TO_9089'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting average wage for to - from\n",
    "data['Avg_Wage'] = np.where(pd.isnull(data['WAGE_OFFER_TO_9089']) == True,data['WAGE_OFFER_FROM_9089'], ((data['WAGE_OFFER_TO_9089']+ data['WAGE_OFFER_FROM_9089']) / 2)) \n",
    "data.WAGE_OFFER_UNIT_OF_PAY_9089.fillna('None', inplace=True)\n",
    "data['WAGE_OFFER_UNIT_OF_PAY_9089'] = data['WAGE_OFFER_UNIT_OF_PAY_9089'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transforming units to yearly equivalents\n",
    "data['unit'] = data['WAGE_OFFER_UNIT_OF_PAY_9089']\n",
    "data['unit'] = data['unit'].replace({\"Hour\": 2080, \"Week\":52,\"Month\":12,\"Bi-Weekly\":26,\"Year\":1,\"None\":np.NaN})\n",
    "data['unit'] = pd.to_numeric(data['unit'])\n",
    "#calculating yearly wage\n",
    "data['Year_wage_offer'] = data['Avg_Wage'] * data['unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing over prevailing wage amounts\n",
    "data['PW_AMOUNT_9089'] = data['PW_AMOUNT_9089'].apply(lambda word: str(word).replace(\"#\", \"\"))\n",
    "data['PW_AMOUNT_9089'] = data['PW_AMOUNT_9089'].apply(lambda word: str(word).replace(\",\", \"\"))\n",
    "data['PW_AMOUNT_9089'] = data['PW_AMOUNT_9089'].replace({\"nan\": np.NaN})\n",
    "data['PW_AMOUNT_9089'] = pd.to_numeric(data['PW_AMOUNT_9089'])\n",
    "data['unit_pw'] = data['PW_UNIT_OF_PAY_9089']\n",
    "data['unit_pw'] = data['unit_pw'].replace({\"Hour\": 2080, \"Week\":52,\"Month\":12,\"Bi-Weekly\":26,\"Year\":1,\"None\":np.NaN})\n",
    "data['unit_pw'] = pd.to_numeric(data['unit_pw'])\n",
    "data['Year_wage_pw'] = data['PW_AMOUNT_9089'] * data['unit_pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filling up the nulls with the medians from the industry / level for both prevailing wage and offer\n",
    "data['Ind_code'] = data['PW_SOC_CODE'].apply(lambda num: str(num)[:2])\n",
    "data['Wage_level'] =  data['PW_LEVEL_9089'].replace({\"Level I\": 1, \"Level II\": 2, \"Level III\":3,\"Level IV\":4}) \n",
    "data['Wage_level'] = data['Wage_level'].fillna(\"None\")\n",
    "norm_wage = pd.DataFrame(data.groupby(['Ind_code','Wage_level'])['Year_wage_pw'].median())\n",
    "norm_wage.columns= [\"Median_pw\"]\n",
    "data['Year_wage_pw'] = data['Year_wage_pw'].fillna(data.merge(norm_wage, how = \"left\", left_on = ['Ind_code','Wage_level'], right_index = True)['Median_pw'])\n",
    "norm_wage_off = pd.DataFrame(data.groupby(['Ind_code','Wage_level'])['Year_wage_offer'].median())\n",
    "norm_wage_off.columns= [\"Median_offer\"]\n",
    "data['Year_wage_offer'] = data['Year_wage_offer'].fillna(data.merge(norm_wage_off, how = \"left\", left_on = ['Ind_code','Wage_level'], right_index = True)['Median_offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visa information transformation\n",
    "#making the VISA column into booleans, if have H1B, if have other, if have none\n",
    "data['CLASS_OF_ADMISSION'] = np.where(data['CLASS_OF_ADMISSION'].isnull(), \"None\", data['CLASS_OF_ADMISSION'])\n",
    "data['H1B_VISA'] = np.where(data['CLASS_OF_ADMISSION'] == \"H-1B\", 1, 0)\n",
    "tmp = np.isin(data['CLASS_OF_ADMISSION'], ['H-1B','None','Not in USA','Parolee'])\n",
    "data['Other_Visa'] = np.where(tmp , 0, 1)\n",
    "tmp = np.isin(data['CLASS_OF_ADMISSION'], ['None','Not in USA','Parolee'])\n",
    "data['No_US_Visa'] = np.where(tmp , 1, 0)\n",
    "#visa_info['No_US_Visa'] = np.where(visa_info['CLASS_OF_ADMISSION']  in ['H-1B','NaN','Not in USA','Parolee'] , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#education level transformation\n",
    "data['Same_education'] = np.where(data['JOB_INFO_EDUCATION'] == data ['FOREIGN_WORKER_INFO_EDUCATION'], 1 , 0 )\n",
    "mapping = {\"Master's\" : 4, \"Bachelor's\": 3, \"None\":0, \"Doctorate\":5 , \"Other\": np.NaN, \"High School\":1, \"Associate's\":2, \"NaN\":np.NaN}\n",
    "\n",
    "data = data.replace({'FOREIGN_WORKER_INFO_EDUCATION': mapping, 'JOB_INFO_EDUCATION': mapping})\n",
    "data['Higher education'] = np.where(data['FOREIGN_WORKER_INFO_EDUCATION'] > data['JOB_INFO_EDUCATION'], 1,0)\n",
    "data['Lower education'] = np.where(data['FOREIGN_WORKER_INFO_EDUCATION'] < data['JOB_INFO_EDUCATION'], 1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recruitment dates transformation\n",
    "data['swa'] = (data['RECR_INFO_SWA_JOB_ORDER_END'] - data['RECR_INFO_SWA_JOB_ORDER_START']).dt.days\n",
    "data['job_fair'] = (data['RECR_INFO_JOB_FAIR_TO'] - data['RECR_INFO_JOB_FAIR_FROM']).dt.days\n",
    "data['campus_fair'] = (data['RECR_INFO_ON_CAMPUS_RECR_TO'] - data['RECR_INFO_ON_CAMPUS_RECR_FROM']).dt.days\n",
    "data['web_post'] = (data['RI_EMPLOYER_WEB_POST_TO'] - data['RI_EMPLOYER_WEB_POST_FROM']).dt.days\n",
    "data['org_ad'] = (data['RECR_INFO_PRO_ORG_ADVERT_TO'] - data['RECR_INFO_PRO_ORG_ADVERT_FROM']).dt.days\n",
    "data['searc_web'] =  (data['RI_JOB_SEARCH_WEBSITE_TO'] - data['RI_JOB_SEARCH_WEBSITE_FROM']).dt.days\n",
    "data['emp_frm'] =  (data['RI_PVT_EMPLOYMENT_FIRM_TO'] - data['RI_PVT_EMPLOYMENT_FIRM_FROM']).dt.days\n",
    "data['ref_prof'] = (data['RI_EMPLOYEE_REFERRAL_PROG_TO'] - data['RI_EMPLOYEE_REFERRAL_PROG_FROM']).dt.days\n",
    "data['campus_pl'] = (data['RI_CAMPUS_PLACEMENT_TO'] - data['RI_CAMPUS_PLACEMENT_FROM']).dt.days\n",
    "data['eth_pp'] = (data['RI_LOCAL_ETHNIC_PAPER_TO'] - data['RI_LOCAL_ETHNIC_PAPER_FROM']).dt.days\n",
    "data['tv_ad'] = (data['RECR_INFO_RADIO_TV_AD_TO'] - data['RECR_INFO_RADIO_TV_AD_FROM']).dt.days\n",
    "data['RECR_INFO_FIRST_AD_START'] = np.where(np.isnat(data['RECR_INFO_FIRST_AD_START']),0,1)\n",
    "data['RECR_INFO_SECOND_AD_START'] = np.where(np.isnat(data['RECR_INFO_SECOND_AD_START']),0,1)\n",
    "data[['job_fair','campus_fair','web_post','org_ad','searc_web','emp_frm','ref_prof','campus_pl','eth_pp','tv_ad']] = data[['job_fair','campus_fair','web_post','org_ad','searc_web','emp_frm','ref_prof','campus_pl','eth_pp','tv_ad']].replace({0.0:1.0})\n",
    "data['Total_rec'] = data[['swa','RECR_INFO_SECOND_AD_START','RECR_INFO_FIRST_AD_START','job_fair','campus_fair','web_post','org_ad','searc_web','emp_frm','ref_prof','campus_pl','eth_pp','tv_ad']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transforming the leftover columns\n",
    "data['JOB_INFO_JOB_REQ_NORMAL'] = np.where((data['JOB_INFO_JOB_REQ_NORMAL']) == \"Y\", 1,0)\n",
    "data['DEC_YEAR'] = pd.DatetimeIndex(data['DECISION_DATE']).year\n",
    "data['LAWYER'] = np.where(pd.isnull(data['AGENT_FIRM_NAME']), 0, 1)\n",
    "data['CASE_STATUS'] = pd.DataFrame(np.where(data['CASE_STATUS'] == 'Certified-Expired' , 'Certified', data['CASE_STATUS']))\n",
    "data['JOB_INFO_FOREIGN_LANG_REQ'] = np.where(data['JOB_INFO_FOREIGN_LANG_REQ'] == \"Y\", 1,0)\n",
    "data['JOB_INFO_COMBO_OCCUPATION'] = np.where((data['JOB_INFO_COMBO_OCCUPATION']) == \"Y\", 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GEtting final data\n",
    "data_fin = data[['CASE_STATUS','JOB_INFO_JOB_REQ_NORMAL','DEC_YEAR','LAWYER','JOB_INFO_FOREIGN_LANG_REQ','JOB_INFO_COMBO_OCCUPATION','Wage_level','Year_wage_offer','Year_wage_pw','Ind_code','Higher education','Lower education','Total_rec','EMPLOYER_YR_ESTAB','H1B_VISA','Other_Visa','No_US_Visa','Same_education']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove rows with withdrawn status\n",
    "data_fin = data_fin[data_fin.CASE_STATUS != \"Withdrawn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#binarize case status\n",
    "data_fin['CASE_STATUS'] = np.where(data_fin['CASE_STATUS'] == \"Certified\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting correlation between all of the variables\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(data_fin.corr(), annot = round(data_fin.corr(), ndigits=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting features from target\n",
    "status = data_fin['CASE_STATUS'].as_matrix()\n",
    "data_ftr = data_fin.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#running logistic model with sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_ftr, status, random_state=0)\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "coef = classifier.coef_[0]\n",
    "print (coef)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.9f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#running logistic model with statsmodels\n",
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the industries graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I made this really stupid I'm sorry but I didn't know how to do it smart\n",
    "wage_graph = data[['Ind_code','Wage_level','Year_wage_offer','Year_wage_pw']]\n",
    "wage_graph['Wage_diff'] = wage_graph['Year_wage_offer'] - wage_graph['Year_wage_pw']\n",
    "wage_dif = pd.DataFrame(wage_graph.groupby(['Ind_code','Wage_level'])['Wage_diff'].median())\n",
    "wage_dif = wage_dif.reset_index()\n",
    "wage_dif['Wage_level'] = np.where(wage_dif['Wage_level'] == 'None', 0,wage_dif['Wage_level'])\n",
    "\n",
    "a = wage_dif[wage_dif['Ind_code'] == '11']\n",
    "b = wage_dif[wage_dif['Ind_code'] == '13']\n",
    "c = wage_dif[wage_dif['Ind_code'] == '15']\n",
    "d = wage_dif[wage_dif['Ind_code'] == '17']\n",
    "e = wage_dif[wage_dif['Ind_code'] == '19']\n",
    "f = wage_dif[wage_dif['Ind_code'] == '20']\n",
    "g = wage_dif[wage_dif['Ind_code'] == '21']\n",
    "h = wage_dif[wage_dif['Ind_code'] == '23']\n",
    "i = wage_dif[wage_dif['Ind_code'] == '25']\n",
    "j = wage_dif[wage_dif['Ind_code'] == '27']\n",
    "k = wage_dif[wage_dif['Ind_code'] == '29']\n",
    "l = wage_dif[wage_dif['Ind_code'] == '30']\n",
    "m = wage_dif[wage_dif['Ind_code'] == '31']\n",
    "n = wage_dif[wage_dif['Ind_code'] == '33']\n",
    "o = wage_dif[wage_dif['Ind_code'] == '35']\n",
    "p = wage_dif[wage_dif['Ind_code'] == '37']\n",
    "q = wage_dif[wage_dif['Ind_code'] == '39']\n",
    "r = wage_dif[wage_dif['Ind_code'] == '41']\n",
    "s = wage_dif[wage_dif['Ind_code'] == '43']\n",
    "t = wage_dif[wage_dif['Ind_code'] == '45']\n",
    "u = wage_dif[wage_dif['Ind_code'] == '47']\n",
    "v = wage_dif[wage_dif['Ind_code'] == '49']\n",
    "w = wage_dif[wage_dif['Ind_code'] == '51']\n",
    "x = wage_dif[wage_dif['Ind_code'] == '53']\n",
    "y = wage_dif[wage_dif['Ind_code'] == '90']\n",
    "z = wage_dif[wage_dif['Ind_code'] == '91']\n",
    "aa = wage_dif[wage_dif['Ind_code'] == 'na']\n",
    "\n",
    "wage_dif['Wage_level'] = wage_dif['Wage_level'].replace({1:'Level 1', 2:'Level 2',3:'Level 3',4:'Level 4',0:\"No level\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(a['Wage_level'], a['Wage_diff'], label = '11')\n",
    "ax.plot(b['Wage_level'], b['Wage_diff'], label = '13')\n",
    "ax.plot(c['Wage_level'], c['Wage_diff'], label = '15')\n",
    "ax.plot(d['Wage_level'], d['Wage_diff'], label = '17')\n",
    "ax.plot(e['Wage_level'], e['Wage_diff'], label = '19')\n",
    "ax.plot(f['Wage_level'], f['Wage_diff'], label = '20')\n",
    "ax.plot(g['Wage_level'], g['Wage_diff'], label = '21')\n",
    "ax.plot(h['Wage_level'], h['Wage_diff'], label = '23')\n",
    "ax.plot(i['Wage_level'], i['Wage_diff'], label = '25')\n",
    "ax.plot(j['Wage_level'], j['Wage_diff'], label = '27')\n",
    "ax.plot(k['Wage_level'], k['Wage_diff'], label = '29')\n",
    "ax.plot(l['Wage_level'], l['Wage_diff'], label = '30')\n",
    "ax.plot(m['Wage_level'], m['Wage_diff'], label = '31')\n",
    "ax.plot(n['Wage_level'], n['Wage_diff'], label = '33')\n",
    "ax.plot(o['Wage_level'], o['Wage_diff'], label = '35')\n",
    "ax.plot(p['Wage_level'], p['Wage_diff'], label = '37')\n",
    "ax.plot(q['Wage_level'], q['Wage_diff'], label = '39')\n",
    "ax.plot(r['Wage_level'], r['Wage_diff'], label = '41')\n",
    "ax.plot(s['Wage_level'], s['Wage_diff'], label = '43')\n",
    "ax.plot(t['Wage_level'], t['Wage_diff'], label = '45')\n",
    "ax.plot(u['Wage_level'], a['Wage_diff'], label = '47')\n",
    "ax.plot(v['Wage_level'], a['Wage_diff'], label = '49')\n",
    "ax.plot(w['Wage_level'], a['Wage_diff'], label = '51')\n",
    "ax.plot(x['Wage_level'], a['Wage_diff'], label = '53')\n",
    "ax.plot(y['Wage_level'], a['Wage_diff'], label = '90')\n",
    "ax.plot(z['Wage_level'], a['Wage_diff'], label = '91')\n",
    "ax.plot(aa['Wage_level'], a['Wage_diff'], label = 'na')\n",
    "\n",
    "\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "#ax.legend()   ------uncomment this to get the legend\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
