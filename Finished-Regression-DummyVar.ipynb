{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn \n",
    "import sklearn.datasets\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from numpy import nan\n",
    "import re\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = pd.read_excel(\"finalSheet.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_outlier(points, thresh=3.5):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        thresh : The modified z-score to use as a threshold. Observations with\n",
    "            a modified z-score (based on the median absolute deviation) greater\n",
    "            than this value will be classified as outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "\n",
    "    References:\n",
    "    ----------\n",
    "        Boris Iglewicz and David Hoaglin (1993), \"Volume 16: How to Detect and\n",
    "        Handle Outliers\", The ASQC Basic References in Quality Control:\n",
    "        Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. \n",
    "    \"\"\"\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_wage = pd.DataFrame(df.groupby(['Ind_code','Wage_level'])['Year_wage_pw'].median())\n",
    "norm_wage_off = pd.DataFrame(df.groupby(['Ind_code','Wage_level'])['Year_wage_offer'].median())\n",
    "norm_wage.columns= [\"Median_pw\"]\n",
    "norm_wage_off.columns= [\"Median_offer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Getting rid of the outliers for the wages\n",
    "df['PW_outlier'] = is_outlier(df['Year_wage_pw'])\n",
    "df['Offer_outlier'] = is_outlier(df['Year_wage_offer'])\n",
    "\n",
    "df.Year_wage_pw.loc[df['PW_outlier'] == True] = (df.loc[df['PW_outlier'] == True].merge(norm_wage, how = \"left\", left_on = ['Ind_code','Wage_level'], right_index = True))['Median_pw']\n",
    "df.Year_wage_offer.loc[df['Offer_outlier'] == True] = (df.loc[df['Offer_outlier'] == True].merge(norm_wage_off, how = \"left\", left_on = ['Ind_code','Wage_level'], right_index = True))['Median_offer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['EducationNA'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==0, 1, 0)\n",
    "df['Education1'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==1, 1, 0)\n",
    "df['Education2'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==2, 1, 0)\n",
    "df['Education3'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==3, 1, 0)\n",
    "df['Education4'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==4, 1, 0)\n",
    "df['Education5'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==5, 1, 0)\n",
    "df['Education6'] = np.where(df['FOREIGN_WORKER_INFO_EDUCATION']==6, 1, 0)\n",
    "df['CitizenRegion1'] = np.where(df['CitizenRegion']==1, 1, 0)\n",
    "df['CitizenRegion2'] = np.where(df['CitizenRegion']==2, 1, 0)\n",
    "df['CitizenRegion3'] = np.where(df['CitizenRegion']==3, 1, 0)\n",
    "df['CitizenRegion4'] = np.where(df['CitizenRegion']==4, 1, 0)\n",
    "df['CitizenRegion5'] = np.where(df['CitizenRegion']==5, 1, 0)\n",
    "df['CitizenRegion6'] = np.where(df['CitizenRegion']==6, 1, 0)\n",
    "df['CitizenRegion7'] = np.where(df['CitizenRegion']==7, 1, 0)\n",
    "df['CitizenRegion8'] = np.where(df['CitizenRegion']==8, 1, 0)\n",
    "df['CitizenRegion9'] = np.where(df['CitizenRegion']==9, 1, 0)\n",
    "df['CitizenRegion10'] = np.where(df['CitizenRegion']==10, 1, 0)\n",
    "df['CitizenRegion11'] = np.where(df['CitizenRegion']==11, 1, 0)\n",
    "df['CitizenRegion12'] = np.where(df['CitizenRegion']==12, 1, 0)\n",
    "df['CitizenRegion13'] = np.where(df['CitizenRegion']==13, 1, 0)\n",
    "df['CitizenRegion14'] = np.where(df['CitizenRegion']==14, 1, 0)\n",
    "df['CitizenRegion15'] = np.where(df['CitizenRegion']==15, 1, 0)\n",
    "df['CitizenRegion16'] = np.where(df['CitizenRegion']==16, 1, 0)\n",
    "df['CitizenRegion17'] = np.where(df['CitizenRegion']==17, 1, 0)\n",
    "df['CitizenRegion18'] = np.where(df['CitizenRegion']==18, 1, 0)\n",
    "df['CitizenRegion19'] = np.where(df['CitizenRegion']==19, 1, 0)\n",
    "df['CitizenRegion20'] = np.where(df['CitizenRegion']==20, 1, 0)\n",
    "df['CitizenRegion21'] = np.where(df['CitizenRegion']==21, 1, 0)\n",
    "df['CitizenRegion22'] = np.where(df['CitizenRegion']==22, 1, 0)\n",
    "df['CitizenRegion23'] = np.where(df['CitizenRegion']==23, 1, 0)\n",
    "df['postalValue0'] = np.where(df['postalValue']==0, 1, 0)\n",
    "df['postalValue1'] = np.where(df['postalValue']==1, 1, 0)\n",
    "df['postalValue2'] = np.where(df['postalValue']==2, 1, 0)\n",
    "df['postalValue3'] = np.where(df['postalValue']==3, 1, 0)\n",
    "df['postalValue4'] = np.where(df['postalValue']==4, 1, 0)\n",
    "df['postalValue5'] = np.where(df['postalValue']==5, 1, 0)\n",
    "df['postalValue6'] = np.where(df['postalValue']==6, 1, 0)\n",
    "df['postalValue7'] = np.where(df['postalValue']==7, 1, 0)\n",
    "df['postalValue8'] = np.where(df['postalValue']==8, 1, 0)\n",
    "df['postalValue9'] = np.where(df['postalValue']==9, 1, 0)\n",
    "df['Ind_Code11'] = np.where(df['Ind_code']==11, 1, 0)\n",
    "df['Ind_Code13'] = np.where(df['Ind_code']==13, 1, 0)\n",
    "df['Ind_Code15'] = np.where(df['Ind_code']==15, 1, 0)\n",
    "df['Ind_Code17'] = np.where(df['Ind_code']==17, 1, 0)\n",
    "df['Ind_Code19'] = np.where(df['Ind_code']==19, 1, 0)\n",
    "df['Ind_Code20'] = np.where(df['Ind_code']==20, 1, 0)\n",
    "df['Ind_Code21'] = np.where(df['Ind_code']==21, 1, 0)\n",
    "df['Ind_Code23'] = np.where(df['Ind_code']==23, 1, 0)\n",
    "df['Ind_Code25'] = np.where(df['Ind_code']==25, 1, 0)\n",
    "df['Ind_Code27'] = np.where(df['Ind_code']==27, 1, 0)\n",
    "df['Ind_Code29'] = np.where(df['Ind_code']==29, 1, 0)\n",
    "df['Ind_Code30'] = np.where(df['Ind_code']==30, 1, 0)\n",
    "df['Ind_Code31'] = np.where(df['Ind_code']==31, 1, 0)\n",
    "df['Ind_Code33'] = np.where(df['Ind_code']==33, 1, 0)\n",
    "df['Ind_Code35'] = np.where(df['Ind_code']==35, 1, 0)\n",
    "df['Ind_Code37'] = np.where(df['Ind_code']==37, 1, 0)\n",
    "df['Ind_Code39'] = np.where(df['Ind_code']==39, 1, 0)\n",
    "df['Ind_Code41'] = np.where(df['Ind_code']==41, 1, 0)\n",
    "df['Ind_Code43'] = np.where(df['Ind_code']==43, 1, 0)\n",
    "df['Ind_Code45'] = np.where(df['Ind_code']==45, 1, 0)\n",
    "df['Ind_Code47'] = np.where(df['Ind_code']==47, 1, 0)\n",
    "df['Ind_Code49'] = np.where(df['Ind_code']==49, 1, 0)\n",
    "df['Ind_Code51'] = np.where(df['Ind_code']==51, 1, 0)\n",
    "df['Ind_Code53'] = np.where(df['Ind_code']==53, 1, 0)\n",
    "df['Ind_Code90'] = np.where(df['Ind_code']==90, 1, 0)\n",
    "df['Ind_Code91'] = np.where(df['Ind_code']==91, 1, 0)\n",
    "df['upperWage'] = np.where(df['Year_wage_offer']>=150000, 1, 0)\n",
    "df['upperMiddleWage'] = np.where((df['Year_wage_offer']>=100000) & (df['Year_wage_offer']<=150000), 1, 0)\n",
    "df['middleWage'] = np.where((df['Year_wage_offer']>=30000) & (df['Year_wage_offer']<=99999), 1, 0)\n",
    "df['povertyWage'] = np.where(df['Year_wage_offer']<=30000, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'EMPLOYER_YR_ESTAB'] *= .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASE_STATUS',\n",
       " 'FOREIGN_WORKER_INFO_EDUCATION',\n",
       " 'JOB_INFO_JOB_REQ_NORMAL',\n",
       " 'CitizenRegion',\n",
       " 'postalValue',\n",
       " 'DEC_YEAR',\n",
       " 'LAWYER',\n",
       " 'JOB_INFO_FOREIGN_LANG_REQ',\n",
       " 'JOB_INFO_COMBO_OCCUPATION',\n",
       " 'Wage_level',\n",
       " 'Year_wage_offer',\n",
       " 'Year_wage_pw',\n",
       " 'Ind_code',\n",
       " 'Higher education',\n",
       " 'Lower education',\n",
       " 'Total_rec',\n",
       " 'EMPLOYER_YR_ESTAB',\n",
       " 'H1B_VISA',\n",
       " 'Other_Visa',\n",
       " 'No_US_Visa',\n",
       " 'Same_education',\n",
       " 'PW_outlier',\n",
       " 'Offer_outlier',\n",
       " 'EducationNA',\n",
       " 'Education1',\n",
       " 'Education2',\n",
       " 'Education3',\n",
       " 'Education4',\n",
       " 'Education5',\n",
       " 'Education6',\n",
       " 'CitizenRegion1',\n",
       " 'CitizenRegion2',\n",
       " 'CitizenRegion3',\n",
       " 'CitizenRegion4',\n",
       " 'CitizenRegion5',\n",
       " 'CitizenRegion6',\n",
       " 'CitizenRegion7',\n",
       " 'CitizenRegion8',\n",
       " 'CitizenRegion9',\n",
       " 'CitizenRegion10',\n",
       " 'CitizenRegion11',\n",
       " 'CitizenRegion12',\n",
       " 'CitizenRegion13',\n",
       " 'CitizenRegion14',\n",
       " 'CitizenRegion15',\n",
       " 'CitizenRegion16',\n",
       " 'CitizenRegion17',\n",
       " 'CitizenRegion18',\n",
       " 'CitizenRegion19',\n",
       " 'CitizenRegion20',\n",
       " 'CitizenRegion21',\n",
       " 'CitizenRegion22',\n",
       " 'CitizenRegion23',\n",
       " 'postalValue0',\n",
       " 'postalValue1',\n",
       " 'postalValue2',\n",
       " 'postalValue3',\n",
       " 'postalValue4',\n",
       " 'postalValue5',\n",
       " 'postalValue6',\n",
       " 'postalValue7',\n",
       " 'postalValue8',\n",
       " 'postalValue9',\n",
       " 'Ind_Code11',\n",
       " 'Ind_Code13',\n",
       " 'Ind_Code15',\n",
       " 'Ind_Code17',\n",
       " 'Ind_Code19',\n",
       " 'Ind_Code20',\n",
       " 'Ind_Code21',\n",
       " 'Ind_Code23',\n",
       " 'Ind_Code25',\n",
       " 'Ind_Code27',\n",
       " 'Ind_Code29',\n",
       " 'Ind_Code30',\n",
       " 'Ind_Code31',\n",
       " 'Ind_Code33',\n",
       " 'Ind_Code35',\n",
       " 'Ind_Code37',\n",
       " 'Ind_Code39',\n",
       " 'Ind_Code41',\n",
       " 'Ind_Code43',\n",
       " 'Ind_Code45',\n",
       " 'Ind_Code47',\n",
       " 'Ind_Code49',\n",
       " 'Ind_Code51',\n",
       " 'Ind_Code53',\n",
       " 'Ind_Code90',\n",
       " 'Ind_Code91',\n",
       " 'upperWage',\n",
       " 'upperMiddleWage',\n",
       " 'middleWage',\n",
       " 'povertyWage']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.astype(int,inplace = True)\n",
    "df = df.drop(['Higher education', 'Lower education','Other_Visa','No_US_Visa','PW_outlier','Offer_outlier','CitizenRegion','postalValue','FOREIGN_WORKER_INFO_EDUCATION','DEC_YEAR','Wage_level','Year_wage_offer','Year_wage_pw','Ind_code', 'Same_education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.09443005e-01   1.79562265e-01  -2.16175743e-01  -3.73639966e-01\n",
      "  -1.41636102e-05   3.43955971e-01   8.05842160e-02   0.00000000e+00\n",
      "   7.67130650e-02  -4.52077773e-02  -9.41832080e-02   2.22104543e-01\n",
      "   2.02984814e-01   6.10445770e-01   2.36975787e-01  -1.76204827e-01\n",
      "   1.48100950e-01   2.54029811e-01  -2.79508104e-02   1.58835331e-01\n",
      "  -1.43956229e-01  -1.68003795e-01  -3.58100283e-02   1.26267558e-01\n",
      "  -5.34748972e-03   2.14425407e-01   1.39349070e-01  -9.56522173e-02\n",
      "   1.87360425e-01   7.57537042e-02   1.53911277e-01   1.71075154e-01\n",
      "   9.31880382e-02  -4.74543633e-02  -9.10934027e-02  -6.51662948e-02\n",
      "  -1.29775848e-01   2.33085666e-01   2.21030266e-01   2.32666297e-01\n",
      "   2.26409371e-01   2.32719299e-01   4.81440566e-01   2.67758413e-01\n",
      "   3.25000214e-01   1.20418790e-01   7.44546916e-02   3.46684582e-01\n",
      "   4.50331009e-01   4.87609344e-01   4.48123935e-01   3.81184619e-01\n",
      "   2.93606073e-01   3.40728884e-01   3.21891645e-01   4.96908818e-02\n",
      "   3.59557837e-01   4.07583532e-01   6.64042457e-01   4.44439342e-01\n",
      "  -2.34770730e-02   4.61237723e-01   4.28003342e-01  -7.36642658e-02\n",
      "   3.70629825e-01   4.17331000e-01   4.99543553e-01   2.62945662e-01\n",
      "   1.10197099e-01   1.02193520e-01   4.53409678e-01   1.14528297e-01\n",
      "   2.26969222e-01   1.13162362e-01   7.41238281e-02  -5.04662667e-02\n",
      "   1.62058219e-02]\n",
      "[[    0  4880]\n",
      " [    0 69521]]\n",
      "Accuracy of logistic regression classifier on test set: 0.93441\n",
      "\n",
      "Presicion: 0.93441\n",
      "\n",
      "Recall: 1.00000\n",
      "\n",
      "F1: 0.96609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,1:]\n",
    "Y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "coef = classifier.coef_[0]\n",
    "print (coef)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.5f}\\n'.format(classifier.score(X_test, y_test)))\n",
    "print('Presicion: {:.5f}\\n'.format(sklearn.metrics.precision_score(y_test,y_pred)))\n",
    "print('Recall: {:.5f}\\n'.format(sklearn.metrics.recall_score(y_test,y_pred)))\n",
    "print('F1: {:.5f}\\n'.format(sklearn.metrics.f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_df =df.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297601, 78)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "ones = sampled_df[sampled_df['CASE_STATUS'] == 1]\n",
    "remove_n = (.66 * ones.count()).astype(int)\n",
    "remove_n = remove_n['CASE_STATUS']\n",
    "drop_indices = np.random.choice(ones.index, remove_n, replace=False)\n",
    "sampled_df = ones.drop(drop_indices)\n",
    "zeros = df[df['CASE_STATUS'] == 0]\n",
    "frames = [zeros,sampled_df]\n",
    "sampled_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20007\n",
       "0    19276\n",
       "Name: CASE_STATUS, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['CASE_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sampled_df.iloc[:,1:]\n",
    "Y = sampled_df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(25,25)) \n",
    "#sns.heatmap(df.corr(), annot = df.corr())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.12830170e-01   1.82438732e-01  -2.28149388e-01  -1.21209009e-01\n",
      "  -6.14904559e-07   3.05272735e-01   8.79870337e-03   0.00000000e+00\n",
      "  -3.13927112e-01  -4.54932156e-01  -3.30286987e-01  -1.66331786e-01\n",
      "  -1.76669366e-01   2.09885144e-01   1.23784782e-01  -2.19846358e-01\n",
      "  -1.80699338e-01   5.11676737e-02   2.55974183e-02   9.51152328e-02\n",
      "  -5.83848985e-02  -3.16691628e-01  -3.20534879e-01   8.98374499e-05\n",
      "  -7.38805987e-02   4.25020482e-02   5.48414254e-02  -1.78581120e-01\n",
      "  -6.49628159e-02  -4.02283825e-02   7.29734563e-03   1.63454301e-01\n",
      "  -7.80894534e-02  -7.29900656e-02   3.62668965e-01  -2.14375646e-01\n",
      "  -3.39516110e-01   2.99930411e-01   2.95867808e-01   3.31342549e-01\n",
      "   3.17761253e-01   3.64142468e-01   5.59894824e-01   3.90767739e-01\n",
      "   4.66645453e-01   2.71247809e-01   1.71260641e-01   6.45241239e-01\n",
      "   6.79177533e-01   6.84627000e-01   5.96968639e-01   5.99616662e-01\n",
      "   2.81605006e-02   2.86256635e-01   8.22218039e-01   2.94847445e-01\n",
      "   6.43513086e-01   4.92007088e-01   8.49948384e-02   6.22756095e-01\n",
      "  -5.46447814e-01   6.81941092e-01   5.69451088e-01   2.05175833e-01\n",
      "   5.83360266e-01   6.69826657e-01   7.55363564e-01   5.96532759e-01\n",
      "   3.98824717e-01   3.32212406e-01   9.30626689e-01   9.90578430e-03\n",
      "   4.06061291e-01  -2.34487817e-02  -1.94563774e-02  -1.87543523e-01\n",
      "  -2.74695826e-02]\n",
      "[[2014 2770]\n",
      " [1462 3575]]\n",
      "Accuracy of logistic regression classifier on test set: 0.56909\n",
      "\n",
      "Presicion: 0.56344\n",
      "\n",
      "Recall: 0.70975\n",
      "\n",
      "F1: 0.62818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "coef = classifier.coef_[0]\n",
    "print (coef)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.5f}\\n'.format(classifier.score(X_test, y_test)))\n",
    "print('Presicion: {:.5f}\\n'.format(sklearn.metrics.precision_score(y_test,y_pred)))\n",
    "print('Recall: {:.5f}\\n'.format(sklearn.metrics.recall_score(y_test,y_pred)))\n",
    "print('F1: {:.5f}\\n'.format(sklearn.metrics.f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'CitizenRegion7'), (1, 'CitizenRegion8'), (1, 'Ind_Code11'), (1, 'Ind_Code13'), (1, 'Ind_Code15'), (1, 'Ind_Code17'), (1, 'Ind_Code19'), (1, 'Ind_Code21'), (1, 'Ind_Code31'), (1, 'Ind_Code33'), (1, 'Ind_Code39'), (1, 'Ind_Code43'), (1, 'Ind_Code51'), (1, 'Ind_Code53'), (1, 'postalValue9'), (2, 'Education5'), (3, 'Ind_Code27'), (4, 'Ind_Code25'), (5, 'Education2'), (6, 'CitizenRegion6'), (7, 'Ind_Code30'), (8, 'CitizenRegion13'), (9, 'postalValue4'), (10, 'CitizenRegion4'), (11, 'CASE_STATUS'), (12, 'Ind_Code41'), (13, 'Ind_Code35'), (14, 'Ind_Code45'), (15, 'Ind_Code49'), (16, 'Ind_Code20'), (17, 'Ind_Code23'), (18, 'Ind_Code47'), (19, 'Ind_Code37'), (20, 'Education1'), (21, 'CitizenRegion22'), (22, 'CitizenRegion18'), (23, 'LAWYER'), (24, 'CitizenRegion19'), (25, 'CitizenRegion17'), (26, 'postalValue6'), (27, 'upperMiddleWage'), (28, 'JOB_INFO_JOB_REQ_NORMAL'), (29, 'Ind_Code29'), (30, 'EducationNA'), (31, 'CitizenRegion10'), (32, 'CitizenRegion2'), (33, 'Ind_Code90'), (34, 'CitizenRegion14'), (35, 'postalValue5'), (36, 'postalValue3'), (37, 'middleWage'), (38, 'upperWage'), (39, 'Ind_Code91'), (40, 'CitizenRegion21'), (41, 'H1B_VISA'), (42, 'Education6'), (43, 'postalValue0'), (44, 'Education4'), (45, 'Education3'), (46, 'Total_rec'), (47, 'postalValue2'), (48, 'CitizenRegion20'), (49, 'postalValue7'), (50, 'CitizenRegion23'), (51, 'postalValue1'), (52, 'CitizenRegion9'), (53, 'CitizenRegion12'), (54, 'CitizenRegion11'), (55, 'CitizenRegion5'), (56, 'CitizenRegion3'), (57, 'JOB_INFO_FOREIGN_LANG_REQ'), (58, 'CitizenRegion16'), (59, 'CitizenRegion15'), (60, 'postalValue8'), (61, 'CitizenRegion1'), (62, 'EMPLOYER_YR_ESTAB'), (63, 'JOB_INFO_COMBO_OCCUPATION'), (64, 'Same_education')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "names = list(df)\n",
    " \n",
    "#use linear regression as the model\n",
    "lr = LogisticRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=15)\n",
    "rfe.fit(X,Y)\n",
    " \n",
    "print(\"Features sorted by their rank:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.643695\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b340915b19d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[0;32m   1376\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[0;32m    203\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[1;31m# up to subclasses to wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
